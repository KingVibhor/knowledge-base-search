# Knowledge-Based RAG Engine (Gemini + ChromaDB)

A lightweight Retrieval-Augmented Generation (RAG) system that lets you upload
documents (PDF, DOCX, TXT, images) and ask questions about them using Google
Gemini models. The system extracts text, embeds it using Gemini embeddings,
stores vectors in ChromaDB, retrieves relevant chunks, and generates an answer
using Gemini 2.0 Flash.

This project is designed to be simple, fast, and easy to extend.

---

## ğŸš€ Features

- Upload PDFs, DOCX, TXT, and Images
- Text extraction + OCR fallback (pdfplumber + Tesseract)
- Chunking and metadata storage
- Gemini-powered embeddings (text-embedding-004)
- ChromaDB vector store (persistent)
- RAG pipeline with Gemini Flash for answer generation
- Clean frontend UI (HTML + JS)
- Fully CORS-enabled backend (FastAPI)
- Works entirely locally (except Gemini API calls)

---

## ğŸ§© Tech Stack

### **Backend**
- Python 3.10
- FastAPI
- ChromaDB (Persistent DB)
- Google Generative AI (Gemini APIs)
- pdfplumber (PDF extraction)
- pytesseract + pdf2image (OCR fallback)
- DOCX parser
- Uvicorn server

### **Frontend**
- HTML / CSS / JavaScript
- Modern, clean minimalistic interface
- AJAX file upload + query system
- Displays answer and sources

---

## ğŸ“ Project Structure

knowledge-based-rag/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py # FastAPI server + routes
â”‚ â”œâ”€â”€ embeddings.py # Gemini embedding functions
â”‚ â”œâ”€â”€ vector_store.py # ChromaDB setup + CRUD
â”‚ â”œâ”€â”€ rag_pipeline.py # Extraction, chunking, ingestion
â”‚ â”œâ”€â”€ llm_client.py # Gemini answer synthesis
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ index.html # Main UI
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ docs/ # Uploaded documents
â”‚ â”œâ”€â”€ vectorstore/ # ChromaDB persistent DB
â”‚
â””â”€â”€ README.md

yaml
Copy code

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ **Install Python 3.10**  
Your system must use **Python 3.10** because newer Python versions break several dependencies.

### 2ï¸âƒ£ Create a virtual environment
cd knowledge-based-rag
python -m venv .venv

makefile
Copy code

Activate:

Windows (PowerShell):
.venv\Scripts\activate

shell
Copy code

### 3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

markdown
Copy code

### 4ï¸âƒ£ Install Tesseract (for image-only PDFs)
Windows:
- Download: https://github.com/UB-Mannheim/tesseract/wiki
- Install
- Add to PATH:
C:\Program Files\Tesseract-OCR\

makefile
Copy code

Verify:
tesseract --version

makefile
Copy code

### 5ï¸âƒ£ Set your Gemini API key
PowerShell:
setx GEMINI_API_KEY "YOUR_KEY"

sql
Copy code

OR create `.env` with:
GEMINI_API_KEY=YOUR_KEY

yaml
Copy code

---

## â–¶ï¸ Run Backend

uvicorn backend.app:app --reload

nginx
Copy code

Backend runs on:
http://127.0.0.1:8000

yaml
Copy code

---

## â–¶ï¸ Run Frontend

cd frontend
python -m http.server 5500

makefile
Copy code

Visit:
http://127.0.0.1:5500/index.html

yaml
Copy code

---

## ğŸ§ª Usage Flow

### 1. Upload Document  
Click **Upload**, select a PDF/DOCX/TXT/Image â†’ backend extracts text â†’ chunks â†’ embeds â†’ stores.

### 2. Ask a Question  
Enter query â†’ backend retrieves relevant chunks â†’ Gemini generates final answer.

### 3. See Output  
UI shows:
- Final Answer
- Sources (file + chunk index)
- Extracted text snippet

---

## ğŸ”¥ Notes

- Works well with real-world messy PDFs.
- Supports OCR auto fallback for scanned/image-only files.
- ChromaDB persists vectors automatically.
- Fully stateless â€” restart server without losing data.

---

## ğŸ§© Future Improvements
- Support multiple collection namespaces
- Add UI for viewing ingested documents
- Add PDF preview before ingestion
- Add Docker support

---

## ğŸ License
MIT License